{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traffic Lights Detector \n",
    "* -- Brook Cheng\n",
    "* -- July 2 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This project is a branch for the [SDCN Capstone Project of Udacity](https://github.com/udacity/CarND-Capstone), in which there are two parts related to the traffic lights: \n",
    "\n",
    "* Traffic Lights Detector\n",
    "* Traffic Lights Classifier\n",
    "\n",
    "In this part, I have trained a deep learning model to detect the traffic lights in pixel-wise level. That is, I ran semantic segmentation work regarding to driving scenes, with two semantic classes: Traffic Lights and Background. After finishing training the model, we apply it to predict semantic results of other new images with/without traffic lights, the results are compelling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies\n",
    "\n",
    "This project requires Python 3.7 and the following Python libraries installed:\n",
    "* [tensorflow-gpu](https://www.tensorflow.org/)\n",
    "* [keras](https://keras.io/)\n",
    "* [opencv-python](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_tutorials.html)\n",
    "* [skimage](https://scikit-image.org/)\n",
    "* [numpy](http://www.numpy.org/)\n",
    "* [argparse](https://docs.python.org/3/library/argparse.html)\n",
    "* [glob](https://docs.python.org/3/library/glob.html)\n",
    "\n",
    "#### Remind: To faciliate traning and testing process, I use a NVIDIA Graphics Card to proceed \n",
    "![NVDIA GeForce GTX 780 Ti](//live.staticflickr.com/65535/48235926726_8ca02a533e_h.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "Dataset for training was provided by Udacity from ros bag (traffic_light_bag_files). It's ignored because files can be downloaded from Udacity website and unpack using RosBag instructions.\n",
    "\n",
    "In this project, we have two different dataset carla and sim, the former is based on the real driving scence and the latter is from the [Autoware](https://github.com/autowarefoundation/autoware) simultor platfrom. Each dataset contains dataset for traning and testing, respectively. Moreover, each pair of images consists of one rgb image and one maks/label. \n",
    "\n",
    "For the maski mages, there are 2 semantic classes: Tarffic Lights and Background\n",
    "![](//live.staticflickr.com/65535/48235925376_0fa2977ebe_b.jpg)\n",
    "\n",
    "Below are examples of images from these two different datasets.\n",
    "\n",
    "#### 1. Exampel from dataset of carla\n",
    "\n",
    "* image -- ![](//live.staticflickr.com/65535/48235762867_ebc343aa99_c.jpg)\n",
    "* mask -- ![](//live.staticflickr.com/65535/48235690456_d84238eb00_c.jpg)\n",
    "\n",
    "#### 2. Exampel from dataset of simulator\n",
    "\n",
    "* image -- ![](//live.staticflickr.com/65535/48235705681_85998d770e_c.jpg)\n",
    "* mask -- ![](//live.staticflickr.com/65535/48235706456_363d0b3c1f_c.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File System"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "./data/\n",
    "      carla/\n",
    "           train/\n",
    "                green/*.jpg\n",
    "                no/*.jpg\n",
    "                red/*.jpg\n",
    "                yellow/*.jpg\n",
    "           test/\n",
    "               green/*.jpg\n",
    "               no/*.jpg\n",
    "               red/*.jpg\n",
    "               yellow/*.jpg\n",
    "       sim/\n",
    "          train/\n",
    "               green/*.jpg\n",
    "               no/*.jpg\n",
    "               red/*.jpg\n",
    "               yellow/*.jpg\n",
    "          test/\n",
    "              green/*.jpg\n",
    "              no/*.jpg\n",
    "              red/*.jpg\n",
    "              yellow/*.jpg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "* Writing the raw data into .npy file, in which all the images have been saved as numpy.darray format.\n",
    "* Cropping each image into specific size.\n",
    "* Transforming RGB images into Gray images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture of Neural Networks\n",
    "\n",
    "For the task of traffic light detection, we adopt [U-Net](https://arxiv.org/abs/1505.04597).\n",
    "\n",
    "As our input image has been resize and grayed into (W,H,C) = (96,128,1). Thereby, the neural network becomes:\n",
    "\n",
    "![](//live.staticflickr.com/65535/48235939971_f0e84f8a8f_b.jpg)\n",
    "![](//live.staticflickr.com/65535/48236019627_469a11b48e_b.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result\n",
    "\n",
    "I have saved the training weights for dataset of carla and sim, both. \n",
    "\n",
    "* tl_weights_detector_carla.h5\n",
    "* tl_weights_detector_sim.h5\n",
    "\n",
    "To quick test our model, you can run:\n",
    "\n",
    "#### python predict.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
